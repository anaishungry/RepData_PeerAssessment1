## inversion are needed again they do not have to be recalculated,
## but can instead be looked up in the cache.
# First, we create a test matrix
Neo<-matrix(1:4,nrow=2,ncol=2)
## This functions creates a cache of the inverted matrix which can
## be accessed later if the computed inversion is required. The
## function first sets & gets the value of the matrix, and then
## sets & gets the value of the inverse matrix
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmatrix <- function(solve) m <<- solve
getmatrix <- function() m
list(set = set, get = get,
setmatrix = setmatrix,
getmatrix = getmatrix)
}
## This function calculates the inverse of the matrix resulting
## from the makeCacheMatrix function after checking to cache for an
## existing value. If it does not find a cache calculation, it
## does it itself using the solve() function.
cacheSolve <- function(x, ...) {
m <- x$getmatrix()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data, ...)
x$setmatrix(m)
m
}
# Now we make a new vector out of the result from plugging our
# matrix into the cache-making function...
Morpheus <-makeCacheMatrix(Neo)
# ... and we plug that resulting vector into our cache-using function
cacheSolve(Morpheus)
solve(Neo)
install.packages("swirl")
library(datasets)
data(iris)
?iris
mean(Sepal.Length)
iris
mean(Sepal.Lenght)
mean(Sepal.Length)
mean(iris$Sepal.Length)
colMeans(iris)
apply(iris[, 1:4], 1, mean)
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
mtcars
tapply(mtcars$cyl, mtcars$mpg, mean)
mean(mtcars$mpg, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
lapply(mtcars, mean)
?mtcars
with(mtcars, tapply(hp, cyl, mean))
209.21429-82.63636
debug(ls)
View(mtcars)
View(iris)
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(iris$Sepal.Length, iris$Species, mean)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
## The folowing is a series of functions allowing the user to cache
## the results of a matrix inversion, so that if the results of the
## inversion are needed again they do not have to be recalculated,
## but can instead be looked up in the cache.
## This functions creates a cache of the inverted matrix which can
## be accessed later if the computed inversion is required. The
## function first sets & gets the value of the matrix, and then
## sets & gets the value of the inverse matrix
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmatrix <- function(solve) m <<- solve
getmatrix <- function() m
list(set = set, get = get,
setmatrix = setmatrix,
getmatrix = getmatrix)
}
## This function calculates the inverse of the matrix resulting
## from the makeCacheMatrix function after checking to cache for an
## existing value. If it does not find a cache calculation, it
## does it itself using the solve() function.
cacheSolve <- function(x, ...) {
m <- x$getmatrix()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data, ...)
x$setmatrix(m)
m
}
## to test:
## Neo<-matrix(1:4,nrow=2,ncol=2)
## Morpheus <-makeCacheMatrix(Neo)
## cacheSolve(Morpheus)
Neo<-matrix(1:4,nrow=2,ncol=2)
Morpheus <-makeCacheMatrix(Neo)
cacheSolve(Morpheus)
file.url4<-("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv ")
download.file(file.url4,destfile="/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data/quiz1data_4.csv",method="curl")
list.files("/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data")
dateDownloaded4<-date()
dateDownloaded4
DT <- fread("pid.csv")
file.url2<-("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx")
download.file(file.url2,destfile="/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data/quiz1data_2.xlsx",method="curl")
list.files("/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data")
dateDownloaded2<-date()
dateDownloaded2
library(xlsx)
thedata2<-read.xlsx("/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data/quiz1data_2.xlsx",sheetIndex=1,header=T)
dat<-thedata2[18:23,7:15]
sum(dat$Zip*dat$Ext,na.rm=T)
dat<-thedata2[7:15,18:23]
sum(dat$Zip*dat$Ext,na.rm=T)
install.packages("knitr")
file.url<-(https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip)
download.file(file.url,destfile="/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Reproducible Research/Assignment1.csv",method="curl")
thedata<-read.csv("/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Reproducible Research/Assignment1.csv")
```{r}
data<-read.csv("~/Documents/My Crap/School Work/Coursera/Data Sceince/Reproducible Research/activity.csv")
attach(data)
```
data<-read.csv("~/Documents/My Crap/School Work/Coursera/Data Sceince/Reproducible Research/activity.csv")
attach(data)
data<-read.csv("~/Documents/My Crap/School Work/Coursera/Data Science/Reproducible Research/activity.csv")
attach(data)
View(data)
hist(data)
hist(steps)
hist(data$date)
hist(date)
colClasses(data)
install.packages("ggplot2")
install.packages("scales")
library(ggplot2)
library(scales)
library(ggplot2)
library(scales)
data$converted <- as.Date(data$date, format="%Y-%m-%d")
ggplot(data, aes(x=converted)) + geom_histogram()
+      opts(axis.text.x = theme_text(angle=90))
data$converted <- as.Date(data$date, format="%Y-%m-%d")
ggplot(data, bidwidth=x,aes(x=converted)) + geom_histogram()
+      opts(axis.text.x = theme_text(angle=90))
ggplot(data)
ggplot(data$converted)
table(data$date)
ggplot(data$date)
data<-read.csv("~/Documents/My Crap/School Work/Coursera/Data Science/Reproducible Research/activity.csv", colClasses=c("numeric", "Date", "numeric"))
attach(data)
data$converted <- as.Date(data$date, format="%Y-%m-%d")
getwd
getwd()
setwd(/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data)
setwd("/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data/")
getwd()
setwd("/Users/Anastassia/Documents/My Crap/School Work/Coursera/Data Science/Getting and Cleaning Data/")
####check if file exists, if not make it!
#if(!file.exists("Quiz1")){
#  dir.create("Quiz1")
#}
####download file!
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="./Quiz1.csv",method="curl")
list.files(".")
dataDownloaded <- date()
dateDownloaded
dateDownloaded <- date()
dateDownloaded
data<-read.csv("./Quiz1.csv")
head(data)
newdata<-subset(data,VAL==24)
newdata
str(newdata)
fileUrl2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl2, destfile="./Quiz1b.csv",method="curl")
list.files(".")
fileUrl2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl2, destfile="./Quiz1b.xlsx",method="curl")
list.files(".")
library(xlsx)
data2<-read.xlsx("/Quiz1b.xlsx",sheetIndex=1,header=TRUE,colIndex=7:15,rowIndex=11:23)
head(data2)
library(rJava)
library(xlsxjars)
library(xlsx)
data2<-read.xlsx("/Quiz1b.xlsx",sheetIndex=1,header=TRUE,colIndex=7:15,rowIndex=11:23)
data2<-read.xlsx("./Quiz1b.xlsx",sheetIndex=1,header=TRUE,colIndex=7:15,rowIndex=11:23)
head(data2)
sum(dat$Zip*dat$Ext,na.rm=T)
dat<-read.xlsx("./Quiz1b.xlsx",sheetIndex=1,header=TRUE,colIndex=7:15,rowIndex=11:23)
head(dat)
sum(dat$Zip*dat$Ext,na.rm=T)
fileUrl3<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl3,destfile="./Quiz1c.xml",method="curl")
list.files(".")
library(XML)
library(XML)
fileUrl3<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileUrl3,useInternal=TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
doc<-xmlTreeParse(fileUrl3,useInternal=TRUE)
fileUrl3<-"http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileUrl3,useInternal=TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
xmlSApply(rootNode,"//zipcode",xmlValue)
xmlSApply(rootNode,"<zipcode>",xmlValue)
xmlSApply(rootNode,"<zipcode>"==21231)
zipcode<-xpathSApply(rootNode,"//zipcode",xmlValue)
a<-table(zipcode)
a[names(a)==21231]
fileUrl4<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="./Quiz1d.csv",method="curl")
list.files(".")
data <- read.csv(unz("activity.csv"), colClasses=c("numeric", "Date", "numeric"))
data <- read.csv(unz("activity.csv"), colClasses=c("numeric", "Date", "numeric"),sep=",")
data<-read.csv("./activity.csv, colClasses=c("numeric", "Date", "numeric"))
data<-read.csv("./activity.csv", colClasses=c("numeric", "Date", "numeric"))
attach(data)
get.wd
getwd()
list.files(".")
set.wd("~/Documents/My Crap/School Work/Coursera/Data Science/Reproducible Research")
setwd("~/Documents/My Crap/School Work/Coursera/Data Science/Reproducible Research")
getwd()
list.files(.)
list.files(".")
setwd("~/Documents/My Crap/School Work/Coursera/Data Science/Reproducible Research/RepData_PeerAssessment1")
list.files(".")
data<-read.csv("./activity.csv", colClasses=c("numeric", "Date", "numeric"))
attach(data)
View(data)
library(ggplot2)
library(scales)
data$converted <- as.Date(data$date, format="%Y-%m-%d")
ggplot(data$date)
head(data)
hist(data$steps)
barplot(data$steps, names.arg=data$data, ylim=c(0,5), ylab="blah", xlab="lol")
barplot(data$steps, names.arg=data$data, ylab="blah", xlab="lol")
countSteps <- aggregate(steps ~ date, activityData, sum)
plot(countSteps$date, countSteps$steps)
countSteps <- aggregate(steps ~ date, data, sum)
plot(countSteps$date, countSteps$steps)
totalsteps <- aggregate(steps ~ date, data, sum)
plot(totalsteps$date, totalsteps$steps)
hist(totalsteps$steps)
hist(totalsteps$steps,breaks=20)
meansteps<-mean(totalsteps$steps)
mediansteps<-median(totalsteps$steps)
intervalsteps <- aggregate(steps ~ interval, data, mean)
hist(intervalsteps$steps,breaks=20,main="Total number of steps taken per day",xlab="Number of steps")
hist(intervalsteps$steps,breaks=20)
plot(intervalsteps$steps,type="l")
intervalsteps <- aggregate(steps ~ interval, data, mean)
plot(intervalsteps$steps,type="l",ylab="Mean number of steps",xlab="5-minute interval",main="Mean number of steps taken in 5-minute intervals averaged across all days")
intervalsteps <- aggregate(steps ~ interval, data, mean)
plot(intervalsteps$steps,type="l",ylab="Mean number of steps",xlab="5-minute interval",main="Mean steps taken in 5-minute intervals averaged across all days")
```{r fig.width=4, fig.height=4, echo=TRUE}
intervalsteps <- aggregate(steps ~ interval, data, mean)
plot(intervalsteps$steps,type="l",ylab="Mean number of steps",xlab="5-minute interval",main="Mean steps taken in 5-minute intervals")
```
?max
maxsteps<-max(intervalsteps$steps,na.rm=TRUE)
maxsteps
?subset
maxsubset<-subset(intervalsteps,steps=="maxsteps")
maxsubset
maxsubset<-subset(intervalsteps,steps==206.1698)
maxsubset
maxsubset<-subset(intervalsteps,steps==maxsteps)
maxsubset
?is.na
is.na(data)
which(is.na(data)
)
missingvalues<-which(is.na(data))
length(missingvalues)
impute.mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
activity.imputed <- plyr::ddply(activity[1:3], .(interval), transform,
steps = impute.mean(steps),
date = date,
interval = interval)
activity.imputed <- plyr::ddply(data[1:3], .(interval), transform,
steps = impute.mean(steps),
date = date,
interval = interval)
data.imputed <- plyr::ddply(data[1:3], .(interval), transform,
steps = impute.mean(steps),
date = date,
interval = interval)
data.imputed <- plyr::ddply(data[1:3], (interval), transform,
steps = impute.mean(steps),
date = date,
interval = interval)
?na.gam.replace
??na.gam.replace
?na.fill
??na.fill
?cast
install.packages("hadley")
install.packages("reshape")
library(reshape)
head(data)
data<-read.csv("./activity.csv", colClasses=c("numeric", "Date", "numeric"))
attach(data)
totalsteps <- aggregate(steps ~ date, data, sum)
hist(totalsteps$steps,breaks=20,main="Total number of steps taken per day",xlab="Number of steps")
meansteps<-mean(totalsteps$steps)
mediansteps<-median(totalsteps$steps)
meansteps
mediansteps
intervalsteps <- aggregate(steps ~ interval, data, mean)
plot(intervalsteps$steps,type="l",ylab="Mean number of steps",xlab="5-minute interval",main="Mean steps taken in 5-minute intervals")
maxsteps<-max(intervalsteps$steps,na.rm=TRUE)
maxsteps
maxsubset<-subset(intervalsteps,steps==maxsteps)
maxsubset
missingvalues<-which(is.na(data))
missingcount<-length(missingvalues)
missingcount
library(reshape)
head(data)
fillna<-cast(data, date, value="uptake", fun.aggregate=mean, margins=TRUE)
fillna<-cast(data, interval, value="uptake", fun.aggregate=mean, margins=TRUE)
fillna<-cast(data, interval, value="uptake", fun.aggregate=mean, margins=TRUE,sep=",")
data[,mean] <- NA
data[,mean] <- NA
data[,meanvalue] <- NA
data[,"meanvalue"] <- NA
View(data)
data$mean <- with(data, ave(steps,interval ) )
View(data)
data$meanvalue <- with(data, ave(interval,steps))
View(data)
data$meanvalue <- with(data, ave(interval~steps))
data$meanvalue <- with(data, ave(steps~interval))
?ave
data$meanvalue <- with(data, ave(steps,interval))
View(data)
data$meanvalue <- with(data, ave(steps,interval,na.rm=T))
View(data)
data$meanvalue <- with(data, ave(steps,interval,na.rm=T,FUN=first))
?with
?na.omit
data$meanvalue <- with(data,na.omit(data),ave(steps,interval,na.rm=T))
data$meanvalue <- with(data,na.exclude(data),ave(steps,interval,na.rm=T))
```{r echo=TRUE}
data$meanvalue <- with(data,na.fail(data),ave(steps,interval,na.rm=T))
?aggregate
data$meanvalue <- aggregate(steps ~ interval, data, mean)
get.mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
new.data<- plyr::ddply(data[1:3], .(interval), transform,
steps = get.mean(steps),
date = date,
interval = interval)
?plyr
install.packages("plyr")
library(plyr)
get.mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
new.data<- plyr::ddply(data[1:3], .(interval), transform,
steps = get.mean(steps),
date = date,
interval = interval)
library(plyr)
get.mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
new.data<- plyr::ddply(data[1:3], .(interval), transform,
steps = get.mean(steps),
date = date,
interval = interval)
new.data <- new.data[order(new.data$date,new.data$interval),]
row.names(new.data) <- 1:nrow(new.data)
new.data
head(new.data)
new.totalsteps <- aggregate(steps ~ date, new.data, sum)
hist(new.totalsteps$steps,breaks=20,main="Total number of steps taken per day",xlab="Number of steps")
new.meansteps<-mean(new.totalsteps$steps)
new.mediansteps<-median(new.totalsteps$steps)
new.meansteps
new.mediansteps
transform(new.data, weekend=as.POSIXlt(date, format='%Y/%m/%d')$wday %in% c(0, 6))
library(plyr)
get.mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
new.data<- plyr::ddply(data[1:3], .(interval), transform,
steps = get.mean(steps),
date = date,
interval = interval)
new.data <- new.data[order(new.data$date,new.data$interval),]
row.names(new.data) <- 1:nrow(new.data)
new.data$weekday<-"weekday"
transform(new.data, weekend=as.POSIXlt(date, format='%Y/%m/%d')$wday %in% c(0, 6))
head(new.data)
transform(new.data, weekend=as.POSIXlt(date, format='%Y/%m/%d')$wday %in% c(0, 6))
new.data2<-transform(new.data, weekend=as.POSIXlt(date, format='%Y/%m/%d')$wday %in% c(0, 6))
new.data2
head(new.data2)
data<-read.csv("./activity.csv", colClasses=c("numeric", "Date", "numeric"))
attach(data)
totalsteps <- aggregate(steps ~ date, data, sum)
hist(totalsteps$steps,breaks=20,main="Total number of steps taken per day",xlab="Number of steps")
meansteps<-mean(totalsteps$steps)
mediansteps<-median(totalsteps$steps)
meansteps
mediansteps
intervalsteps <- aggregate(steps ~ interval, data, mean)
plot(intervalsteps$steps,type="l",ylab="Mean number of steps",xlab="5-minute interval",main="Mean steps taken in 5-minute intervals")
maxsteps<-max(intervalsteps$steps,na.rm=TRUE)
maxsteps
maxsubset<-subset(intervalsteps,steps==maxsteps)
maxsubset
missingvalues<-which(is.na(data))
missingcount<-length(missingvalues)
missingcount
library(plyr)
get.mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
new.data<- plyr::ddply(data[1:3], .(interval), transform,
steps = get.mean(steps),
date = date,
interval = interval)
new.data <- new.data[order(new.data$date,new.data$interval),]
row.names(new.data) <- 1:nrow(new.data)
new.totalsteps <- aggregate(steps ~ date, new.data, sum)
hist(new.totalsteps$steps,breaks=20,main="Total number of steps taken per day",xlab="Number of steps")
new.meansteps<-mean(new.totalsteps$steps)
new.mediansteps<-median(new.totalsteps$steps)
new.meansteps
new.mediansteps
new.data2<-transform(new.data, weekend=as.POSIXlt(date, format='%Y/%m/%d')$wday %in% c(0, 6))
new.data$day<-"weekday"
new.data2$day<-"weekday"
head(new.data2)
?transform
new.data2$day<-"weekday"
new.data2$weekday <- as.character(new.data2$weekday)
new.data2$weekday[new.data2$weekday == "TRUE"] <- "weekend"
new.data2$day<-"weekday"
within(new.data2, levels(day)[levels(weekend) == "TRUE"] <- "weekend")
head(new.data2)
within(new.data2, levels(day)[levels(weekend) == "TRUE"] <- "weekend")
within(new.data2, levels(weekend)[levels(day) == "TRUE"] <- "weekend")
new.data3<-within(new.data2, levels(day)[levels(weekend) == "TRUE"] <- "weekend")
head(new.data3)
View(new.data3)
new.data3
?levels
?ifelse
ifelse(new.data2$weekend %in% "TRUE","weekend", new.data$day)
new.data3<-ifelse(new.data2$weekend %in% "TRUE","weekend", new.data$day)
head(new.data3)
new.data2$day<-new.data3
View(new.data2)
new.data2
head(new.data2)
new.intervalsteps <- aggregate(steps ~ interval+day, new.data2, mean)
plot(new.intervalsteps$steps,type="l",ylab="Mean number of steps",xlab="5-minute interval",main="Mean steps taken in 5-minute intervals")
View(new.intervalsteps)
?densityplot
??densityplot
library(lattice)
?densityplot
library(lattice)
library(gplots)
install.packages("gplots")
library(lattice)
library(gplots)
plot(new.intervalsteps)
plot.design(new.intervalsteps,main="Main effects")
xyplot(day~interval|steps)
xyplot(interval~day|steps)
xyplot(new.intervalsteps,interval~day|steps)
densityplot(new.intervalsteps$steps)
?densityplot
densityplot(new.intervalsteps$steps|new.intervaldata$interval,new.intervaldata)
densityplot(new.intervalsteps$steps|new.intervaldata$interval,new.intervaldata$day)
densityplot(new.intervalsteps$steps|new.intervalsteps$interval,new.intervalsteps$day)
head(new.intervalsteps)
?as.factor
as.factor(new.intervalsteps$day)
new.intervalsteps$day <-as.factor(new.intervalsteps$day)
densityplot(new.intervalsteps$steps|new.intervalsteps$interval,new.intervalsteps$day)
new.data2<-transform(new.data, weekend=as.POSIXlt(date, format='%Y/%m/%d')$wday %in% c(0, 6))
new.data2$day<-"weekday"
new.data3<-ifelse(new.data2$weekend %in% "TRUE","weekend", new.data$day)
new.data2$day<-new.data3
